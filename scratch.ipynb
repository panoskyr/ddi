{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "import torch_geometric \n",
    "import myutils\n",
    "import models\n",
    "import networkx as nx\n",
    "#from models import SAGE,DotProductLinkPredictor\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch_geometric.utils import negative_sampling,convert\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "dataset_name='ogbl-ddi'\n",
    "dataset=PygLinkPropPredDataset(name=dataset_name)\n",
    "data=dataset[0]\n",
    "adj_t=PygLinkPropPredDataset(name=dataset_name,transform=torch_geometric.transforms.ToSparseTensor('coo'))[0].adj_t.to(device)\n",
    "#use to_undirected to get some metrics\n",
    "G=convert.to_networkx(data,to_undirected=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_embeddings=torch.ones(data.num_nodes, 1).to(device=device)\n",
    "split_edge=dataset.get_edge_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7310, 0.7311, 0.7311,\n",
       "        0.7311], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize our model and LinkPredictor\n",
    "hidden_dimension = 256\n",
    "model = models.SAGE(1, hidden_dimension, hidden_dimension, 7, 0.5).to(device)\n",
    "predictor = models.DotProductLinkPredictor().to(device)\n",
    "\n",
    "# Run our initial \"node features\" through the GNN to get node embeddings\n",
    "model.eval()\n",
    "predictor.eval()\n",
    "h = model(initial_embeddings, adj_t)\n",
    "\n",
    "# Randomly sample some training edges and pass them through our basic predictor\n",
    "torch.manual_seed(1955)\n",
    "idx = torch.randperm(split_edge['train']['edge'].size(0))[:10]\n",
    "edges = split_edge['train']['edge'][idx].t()\n",
    "predictor(h[edges[0]], h[edges[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_batch(all_pos_train_edges,perm,edge_index):\n",
    "    pos_edges=all_pos_train_edges[perm].t().to(device)\n",
    "\n",
    "    #produce as many negative edges as positive edges\n",
    "    neg_edges=negative_sampling(edge_index, num_neg_samples=perm.shape[0], method='dense').to(device)\n",
    "    training_edges=torch.cat([pos_edges, neg_edges], dim=1)\n",
    "\n",
    "    pos_labels=torch.ones(pos_edges.shape[1], dtype=torch.float, device=device)\n",
    "    neg_labels=torch.zeros(neg_edges.shape[1], dtype=torch.float, device=device)\n",
    "\n",
    "    training_labels=torch.cat([pos_labels, neg_labels], dim=0).to(device)\n",
    "\n",
    "    return training_edges, training_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a training batch of size 64 produces a training batch with size 128--> produces 64 real edges and 64 fake edges (total 64 training examples)\n",
    "src_edges= [1 X 128]-->64 real and 64 fake edges of source\n",
    "dest_edges=[1 X 128]--> 64 real and 64 fake destinations\n",
    "\n",
    "training edges=[src_edges,\n",
    "                dest_edges]= [ 2 X \n",
    "                                [1 X 128]\n",
    "                                ]\n",
    "\n",
    "training_labels=[1 X 128] 64 ones and 64 zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4797570850202429\n",
      "0.5159165751920965\n",
      "0.11585760517799353\n",
      "0.3251088534107402\n",
      "0.4250886524822695\n",
      "0.4798792756539235\n",
      "0.280359820089955\n",
      "0.24956672443674177\n",
      "0.3878787878787879\n",
      "0.2648648648648649\n",
      "0.23351063829787233\n",
      "0.6697530864197531\n",
      "0.36221498371335503\n",
      "0.6227951153324288\n",
      "0.33683749452474815\n",
      "0.061630218687872766\n",
      "0.18518518518518517\n",
      "0.3333333333333333\n",
      "0.14728148657949072\n",
      "0.5658914728682171\n",
      "0.4575342465753425\n",
      "0.28593272171253825\n",
      "0.5910326086956522\n",
      "0.31241655540720964\n",
      "0.24108416547788872\n",
      "0.26693629929221435\n",
      "0.13542688910696762\n",
      "0.18377088305489261\n",
      "0.14265734265734265\n",
      "0.19063360881542699\n",
      "0.35687453042824946\n",
      "0.3344343517753922\n",
      "0.28254847645429365\n",
      "0.13083497698882315\n",
      "0.3620689655172414\n",
      "0.2061114439784302\n",
      "0.5133950316609839\n",
      "0.4028203556100552\n",
      "0.28233351678591084\n",
      "0.7471698113207547\n",
      "0.4275109170305677\n",
      "0.18896321070234115\n",
      "0.6666666666666666\n",
      "0.11558854718981973\n",
      "0.3962025316455696\n",
      "0.3932788374205268\n",
      "0.3033075299085151\n",
      "0.10325318246110325\n",
      "0.23142250530785563\n",
      "0.18181818181818182\n",
      "0.3749235474006116\n",
      "0.4088669950738916\n",
      "0.43148148148148147\n",
      "0.011111111111111112\n",
      "0.2686868686868687\n",
      "0.2450381679389313\n",
      "0.1682008368200837\n",
      "0.1629746835443038\n",
      "0.8566666666666667\n",
      "0.36879432624113473\n",
      "0.2667834208990076\n",
      "0.5106861642294713\n",
      "0.41793203181489513\n",
      "0.3221024258760108\n",
      "0.10048309178743961\n",
      "0.07627118644067797\n",
      "0.0\n",
      "0.16319895968790638\n",
      "0.0\n",
      "0.0392156862745098\n",
      "0.15815959741193386\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.003703703703703704\n",
      "0.47246376811594204\n",
      "0.10915492957746478\n",
      "0.0\n",
      "0.22020725388601037\n",
      "0.017679558011049725\n",
      "0.1169811320754717\n",
      "0.03476946334089191\n",
      "0.0\n",
      "0.3211722488038278\n",
      "0.0\n",
      "0.14804469273743018\n",
      "0.06734992679355783\n",
      "0.012371134020618556\n",
      "0.24447513812154695\n",
      "0.01012829169480081\n",
      "0.12441679626749612\n",
      "0.4207708779443255\n",
      "0.053881278538812784\n",
      "0.056155507559395246\n",
      "0.034482758620689655\n",
      "0.016842105263157894\n",
      "0.0\n",
      "0.02553191489361702\n",
      "0.04932735426008968\n",
      "0.0\n",
      "0.02478134110787172\n",
      "0.0\n",
      "0.05489614243323442\n",
      "0.0\n",
      "0.043173862310385065\n",
      "0.12835820895522387\n",
      "0.03608736942070275\n",
      "0.07708333333333334\n",
      "0.010973936899862825\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.13818181818181818\n",
      "0.0681063122923588\n",
      "0.0\n",
      "0.1747700394218134\n",
      "0.1286549707602339\n",
      "0.004103967168262654\n",
      "0.0038560411311053984\n",
      "0.07536557930258718\n",
      "0.023255813953488372\n",
      "0.018018018018018018\n",
      "0.09350237717908082\n",
      "0.027158098933074686\n",
      "0.0\n",
      "0.07991660875608061\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "kk,kl=create_train_batch(split_edge['train']['edge'],torch.randperm(n=split_edge['train']['edge'].size(0))[:batch_size],data.edge_index)\n",
    "\n",
    "for(src_node,dst_node) in list(zip(kk[0],kk[1])):\n",
    "\n",
    "    preds = nx.jaccard_coefficient(G, [(src_node.item(), dst_node.item())])\n",
    "    print(list(*preds)[2]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1391170431211499"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "preds = nx.jaccard_coefficient(G, [(kk[0][0].item(), kk[0][1].item())])\n",
    "list(*preds)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, predictor, x, adj_t, split_edge, loss_fn, optimizer, batch_size, num_epochs):\n",
    "  # adj_t isn't used everywhere in PyG yet, so we switch back to edge_index for negative sampling\n",
    "  # row, col, edge_attr = adj_t.t().coo()\n",
    "  # edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "  edge_index=PygLinkPropPredDataset(name='ogbl-ddi')[0].edge_index.to(device)\n",
    "  model.train()\n",
    "  predictor.train()\n",
    "\n",
    "  model.reset_parameters()\n",
    "  predictor.reset_parameters()\n",
    "  loss_per_epoch = []\n",
    "  all_pos_train_edges = split_edge['train']['edge']\n",
    "  for epoch in range(num_epochs):\n",
    "    epoch_total_loss = 0\n",
    "    for perm in DataLoader(range(all_pos_train_edges.shape[0]), batch_size,\n",
    "                           shuffle=True):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      train_edge, train_label = create_train_batch(all_pos_train_edges, perm, edge_index)\n",
    "\n",
    "\n",
    "      h = model(x, adj_t)\n",
    "\n",
    "      # Get predictions for our batch and compute the loss\n",
    "      preds = predictor(h[train_edge[0]], h[train_edge[1]])\n",
    "      loss = loss_fn(preds, train_label)\n",
    "\n",
    "      epoch_total_loss += loss.item()\n",
    "\n",
    "      # Update our parameters\n",
    "      # pass the loss of the current training batch backwards\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "      torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "    loss_per_epoch.append(epoch_total_loss)\n",
    "    myutils.draw_metric_per_epoch(loss_per_epoch, \"Loss per epoch\", \"Loss\", \"Epoch\", \"loss_per_epoch\")\n",
    "    print(f'Epoch {epoch} has loss {round(epoch_total_loss, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Expected input format of Evaluator for ogbl-ddi\n",
      "{'y_pred_pos': y_pred_pos, 'y_pred_neg': y_pred_neg}\n",
      "- y_pred_pos: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "- y_pred_neg: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "y_pred_pos is the predicted scores for positive edges.\n",
      "y_pred_neg is the predicted scores for negative edges.\n",
      "Note: As the evaluation metric is ranking-based, the predicted scores need to be different for different edges.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#turn off gradient tracking for test\n",
    "@torch.no_grad()\n",
    "def test(model, predictor, x, adj_t, split_edge, evaluator, batch_size):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    \n",
    "    h = model(x, adj_t)\n",
    "\n",
    "    pos_eval_edge = split_edge['edge'].to(device)\n",
    "    neg_eval_edge = split_edge['edge_neg'].to(device)\n",
    "\n",
    "    pos_eval_preds = []\n",
    "    for perm in DataLoader(range(pos_eval_edge.shape[0]), batch_size):\n",
    "        edge = pos_eval_edge[perm].t()\n",
    "        pos_eval_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_eval_pred = torch.cat(pos_eval_preds, dim=0)\n",
    "\n",
    "    neg_eval_preds = []\n",
    "    for perm in DataLoader(range(neg_eval_edge.size(0)), batch_size):\n",
    "        edge = neg_eval_edge[perm].t()\n",
    "        neg_eval_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_eval_pred = torch.cat(neg_eval_preds, dim=0)\n",
    "\n",
    "    total_preds = torch.cat((pos_eval_pred, neg_eval_pred), dim=0)\n",
    "    labels = torch.cat((torch.ones_like(pos_eval_pred), torch.zeros_like(neg_eval_pred)), dim=0)\n",
    "    acc = models.BinaryAccuracy(total_preds, labels)\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30, 40, 50]:\n",
    "        evaluator.K = K\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_eval_pred,\n",
    "            'y_pred_neg': neg_eval_pred,\n",
    "        })[f'hits@{K}']\n",
    "        results[f'Hits@{K}'] = (valid_hits)\n",
    "    results['Accuracy'] = acc\n",
    "\n",
    "    return results\n",
    "eval = Evaluator(name='ogbl-ddi')\n",
    "# ogb Evaluators can be invoked to get their expected format\n",
    "print(eval.expected_input_format) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\scratch.ipynb Cell 11\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# SAGE AND neural LINK PREDICTOR\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m             \u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39mparameters())  \u001b[39m+\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m             \u001b[39mlist\u001b[39m(predictor\u001b[39m.\u001b[39mparameters()), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m train(model, predictor, initial_embeddings, adj_t, split_edge, torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mBCELoss(), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m       optimizer, \u001b[39m64\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m1024\u001b[39;49m, \u001b[39m10\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m test(model, predictor, initial_embeddings, adj_t, split_edge[\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m], Evaluator(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mogbl-ddi\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m64\u001b[39m\u001b[39m*\u001b[39m\u001b[39m1024\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\scratch.ipynb Cell 11\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m train_edge, train_label \u001b[39m=\u001b[39m create_train_batch(all_pos_train_edges, perm, edge_index)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m h \u001b[39m=\u001b[39m model(x, adj_t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Get predictions for our batch and compute the loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m preds \u001b[39m=\u001b[39m predictor(h[train_edge[\u001b[39m0\u001b[39m]], h[train_edge[\u001b[39m1\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\models.py:58\u001b[0m, in \u001b[0;36mSAGE.forward\u001b[1;34m(self, x, adj_t)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, adj_t):\n\u001b[0;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m---> 58\u001b[0m         x \u001b[39m=\u001b[39m conv(x, adj_t)\n\u001b[0;32m     59\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     60\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m    128\u001b[0m     x \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mrelu(), x[\u001b[39m1\u001b[39m])\n\u001b[0;32m    130\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, size\u001b[39m=\u001b[39;49msize)\n\u001b[0;32m    132\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_l(out)\n\u001b[0;32m    134\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:426\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39m# Run \"fused\" message and aggregation (if applicable).\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[39mif\u001b[39;00m is_sparse(edge_index) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplain:\n\u001b[1;32m--> 426\u001b[0m     coll_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fused_user_args, edge_index, size,\n\u001b[0;32m    427\u001b[0m                               kwargs)\n\u001b[0;32m    429\u001b[0m     msg_aggr_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\n\u001b[0;32m    430\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmessage_and_aggregate\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[0;32m    431\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_and_aggregate_forward_pre_hooks\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:341\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[1;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m         out[arg] \u001b[39m=\u001b[39m data\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n\u001b[1;32m--> 341\u001b[0m     indices, values \u001b[39m=\u001b[39m to_edge_index(edge_index)\n\u001b[0;32m    342\u001b[0m     out[\u001b[39m'\u001b[39m\u001b[39madj_t\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m edge_index\n\u001b[0;32m    343\u001b[0m     out[\u001b[39m'\u001b[39m\u001b[39medge_index\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\utils\\sparse.py:248\u001b[0m, in \u001b[0;36mto_edge_index\u001b[1;34m(adj)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[39mreturn\u001b[39;00m adj\u001b[39m.\u001b[39mindices()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mlong(), adj\u001b[39m.\u001b[39mvalues()\n\u001b[0;32m    247\u001b[0m \u001b[39mif\u001b[39;00m adj\u001b[39m.\u001b[39mlayout \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39msparse_csr:\n\u001b[1;32m--> 248\u001b[0m     row \u001b[39m=\u001b[39m ptr2index(adj\u001b[39m.\u001b[39;49mcrow_indices()\u001b[39m.\u001b[39;49mdetach())\n\u001b[0;32m    249\u001b[0m     col \u001b[39m=\u001b[39m adj\u001b[39m.\u001b[39mcol_indices()\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m    250\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack([row, col], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mlong(), adj\u001b[39m.\u001b[39mvalues()\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\utils\\sparse.py:315\u001b[0m, in \u001b[0;36mptr2index\u001b[1;34m(ptr)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mptr2index\u001b[39m(ptr: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    314\u001b[0m     ind \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(ptr\u001b[39m.\u001b[39mnumel() \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mptr\u001b[39m.\u001b[39mdtype, device\u001b[39m=\u001b[39mptr\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m ind\u001b[39m.\u001b[39;49mrepeat_interleave(ptr[\u001b[39m1\u001b[39;49m:] \u001b[39m-\u001b[39;49m ptr[:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SAGE AND CONCAT NEURAL LINK PREDICTOR\n",
    "# Initialize our model and LinkPredictor\n",
    "hidden_dimension = 256\n",
    "model = models.SAGE(1, hidden_dimension, hidden_dimension, 7, 0.5).to(device)\n",
    "predictor = models.ConcatNeuralLinkPredictor(hidden_dimension,hidden_dimension,1,4,0.5).to(device)\n",
    "\n",
    "# Run our initial \"node features\" through the GNN to get node embeddings\n",
    "model.eval()\n",
    "predictor.eval()\n",
    "h = model(initial_embeddings, adj_t)\n",
    "\n",
    "\n",
    "# SAGE AND neural LINK PREDICTOR\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, initial_embeddings, adj_t, split_edge, torch.nn.BCELoss(), \n",
    "      optimizer, 64*1024, 10)\n",
    "test(model, predictor, initial_embeddings, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAGE AND NEURAL LINK PREDICTOR\n",
    "# Initialize our model and LinkPredictor\n",
    "hidden_dimension = 256\n",
    "model = models.SAGE(1, hidden_dimension, hidden_dimension, 7, 0.5).to(device)\n",
    "predictor = models.NeuralLinkPredictor(hidden_dimension,hidden_dimension,1,4,0.5).to(device)\n",
    "\n",
    "# Run our initial \"node features\" through the GNN to get node embeddings\n",
    "model.eval()\n",
    "predictor.eval()\n",
    "h = model(initial_embeddings, adj_t)\n",
    "\n",
    "\n",
    "# SAGE AND neural LINK PREDICTOR\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, initial_embeddings, adj_t, split_edge, torch.nn.BCELoss(), \n",
    "      optimizer, 64*1024, 10)\n",
    "test(model, predictor, initial_embeddings, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAGE AND DOT LINK PREDICTOR\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, initial_embeddings, adj_t, split_edge, torch.nn.BCELoss(), \n",
    "      optimizer, 64*1024, 5)\n",
    "test(model, predictor, initial_embeddings, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why our basic SAGE model performs poorly\n",
    "The node embeddings that are produced do not have any information regarding other measures such as centrality. We will try and enhance our initial embeddings with other metrics before passing them to our SAGE model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding with some metrics\n",
    "# change the function to get training batches to generate additional measures\n",
    "# for the embeddings\n",
    "\n",
    "def train_w_metrics(model, predictor, x, adj_t, split_edge, loss_fn, optimizer, batch_size, num_epochs):\n",
    "  # adj_t isn't used everywhere in PyG yet, so we switch back to edge_index for negative sampling\n",
    "  # row, col, edge_attr = adj_t.t().coo()\n",
    "  # edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "  edge_index=PygLinkPropPredDataset(name='ogbl-ddi')[0].edge_index.to(device)\n",
    "  model.train()\n",
    "  predictor.train()\n",
    "\n",
    "  model.reset_parameters()\n",
    "  predictor.reset_parameters()\n",
    "  loss_per_epoch = []\n",
    "  all_pos_train_edges = split_edge['train']['edge']\n",
    "  for epoch in range(num_epochs):\n",
    "    epoch_total_loss = 0\n",
    "    for perm in DataLoader(range(all_pos_train_edges.shape[0]), batch_size,\n",
    "                           shuffle=True):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      train_edge, train_label = create_train_batch(all_pos_train_edges, perm, edge_index)\n",
    "      \n",
    "      # calculate embeddings and metrics for all the nodes in the training batch\n",
    "      \n",
    "      for(src_node,dst_node) in list(zip(train_edge[0],train_edge[1])):\n",
    "\n",
    "        preds = nx.jaccard_coefficient(G, [(src_node.item(), dst_node.item())])\n",
    "        score=list(*preds)[2] \n",
    "        x[src_node][5]=score \n",
    "        x[dst_node][5]=score\n",
    "        #x[_][5]=nx.resource_allocation_index(G,[(train_edge[0][_],train_edge[1][_])])\n",
    "        #x[_][6]=nx.adamic_adar_index(G,[(train_edge[0][_],train_edge[1][_])])\n",
    "        #x[_][7]=nx.preferential_attachment(G,[(train_edge[0][_],train_edge[1][_])])\n",
    "        \n",
    "\n",
    "\n",
    "      #pass the augmented embeddings into sage to transform them\n",
    "      h = model(x, adj_t)\n",
    "\n",
    "      # Get predictions for our batch and compute the loss\n",
    "      preds = predictor(h[train_edge[0]], h[train_edge[1]])\n",
    "      loss = loss_fn(preds, train_label)\n",
    "\n",
    "      epoch_total_loss += loss.item()\n",
    "\n",
    "      # Update our parameters\n",
    "      # pass the loss of the current training batch backwards\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "      torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "    loss_per_epoch.append(epoch_total_loss)\n",
    "    myutils.draw_metric_per_epoch(loss_per_epoch, \"Loss per epoch\", \"Loss\", \"Epoch\", \"loss_per_epoch\")\n",
    "    print(f'Epoch {epoch} has loss {round(epoch_total_loss, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the saved txt are 0-based to be consistent with the node ids in the graph\n",
    "\n",
    "augmented_embeddings = torch.ones((len(G.nodes)), 5, dtype=torch.float64).to(device)\n",
    "clustering_coef_dict=myutils.load_data_from_txt(\"clustering_coef\")\n",
    "betweenness_dict=myutils.load_data_from_txt(\"betweeness_centrality\")\n",
    "pagerank_dict=myutils.load_data_from_txt(\"pagerank\")\n",
    "for i in range(G.number_of_nodes()):\n",
    "    augmented_embeddings[i][0]=clustering_coef_dict[i]\n",
    "    augmented_embeddings[i][1]=betweenness_dict[i]\n",
    "    augmented_embeddings[i][2]=pagerank_dict[i]\n",
    "    augmented_embeddings[i][3]=G.degree[i]\n",
    "    augmented_embeddings[i][4]=1.0\n",
    "augmented_embeddings=augmented_embeddings.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\scratch.ipynb Cell 17\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#h = model(augmented_init_embeddings, adj_t)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# SAGE AND neural LINK PREDICTOR\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m             \u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39mparameters())  \u001b[39m+\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m             \u001b[39mlist\u001b[39m(predictor\u001b[39m.\u001b[39mparameters()), lr\u001b[39m=\u001b[39m\u001b[39m0.005\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m train(model, predictor, augmented_init_embeddings, adj_t, split_edge, torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mBCELoss(), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m       optimizer, \u001b[39m64\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m1024\u001b[39;49m, \u001b[39m100\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m test(model, predictor, augmented_init_embeddings, adj_t, split_edge[\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m], Evaluator(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mogbl-ddi\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m64\u001b[39m\u001b[39m*\u001b[39m\u001b[39m1024\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\scratch.ipynb Cell 17\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m train_edge, train_label \u001b[39m=\u001b[39m create_train_batch(all_pos_train_edges, perm, edge_index)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m h \u001b[39m=\u001b[39m model(x, adj_t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Get predictions for our batch and compute the loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m preds \u001b[39m=\u001b[39m predictor(h[train_edge[\u001b[39m0\u001b[39m]], h[train_edge[\u001b[39m1\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\models.py:58\u001b[0m, in \u001b[0;36mSAGE.forward\u001b[1;34m(self, x, adj_t)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, adj_t):\n\u001b[0;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m---> 58\u001b[0m         x \u001b[39m=\u001b[39m conv(x, adj_t)\n\u001b[0;32m     59\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     60\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m    128\u001b[0m     x \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mrelu(), x[\u001b[39m1\u001b[39m])\n\u001b[0;32m    130\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, size\u001b[39m=\u001b[39;49msize)\n\u001b[0;32m    132\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_l(out)\n\u001b[0;32m    134\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:435\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m         edge_index, msg_aggr_kwargs \u001b[39m=\u001b[39m res\n\u001b[1;32m--> 435\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage_and_aggregate(edge_index, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmsg_aggr_kwargs)\n\u001b[0;32m    436\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_and_aggregate_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m    437\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (edge_index, msg_aggr_kwargs), out)\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:150\u001b[0m, in \u001b[0;36mSAGEConv.message_and_aggregate\u001b[1;34m(self, adj_t, x)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(adj_t, SparseTensor):\n\u001b[0;32m    149\u001b[0m     adj_t \u001b[39m=\u001b[39m adj_t\u001b[39m.\u001b[39mset_value(\u001b[39mNone\u001b[39;00m, layout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 150\u001b[0m \u001b[39mreturn\u001b[39;00m spmm(adj_t, x[\u001b[39m0\u001b[39;49m], reduce\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggr)\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\utils\\spmm.py:80\u001b[0m, in \u001b[0;36mspmm\u001b[1;34m(src, other, reduce)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39m# Use the default code path for `sum` reduction (works on CPU/GPU):\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mmm(src, other)\n\u001b[0;32m     82\u001b[0m \u001b[39m# Use the default code path with custom reduction (works on CPU):\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m src\u001b[39m.\u001b[39mlayout \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39msparse_csr \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m src\u001b[39m.\u001b[39mis_cuda:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SAGE AND NEURAL LINK PREDICTOR and augmented embeddings\n",
    "# Initialize our model and LinkPredictor\n",
    "hidden_dimension = 256\n",
    "model = models.SAGE(5, hidden_dimension, hidden_dimension, 5, 0.5).to(device)\n",
    "predictor = models.NeuralLinkPredictor(hidden_dimension,hidden_dimension,1,4,0.5).to(device)\n",
    "\n",
    "# Run our initial \"node features\" through the GNN to get node embeddings\n",
    "model.eval()\n",
    "predictor.eval()\n",
    "augmented_init_embeddings=augmented_embeddings\n",
    "#h = model(augmented_init_embeddings, adj_t)\n",
    "\n",
    "\n",
    "# SAGE AND neural LINK PREDICTOR\n",
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.005)\n",
    "train(model, predictor, augmented_init_embeddings, adj_t, split_edge, torch.nn.BCELoss(), \n",
    "      optimizer, 64*1024, 100)\n",
    "test(model, predictor, augmented_init_embeddings, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
