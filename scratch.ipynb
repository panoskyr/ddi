{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\utils\\sparse.py:176: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ..\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:56.)\n",
      "  return adj.to_sparse_csr()\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "import torch_geometric \n",
    "import myutils\n",
    "import models\n",
    "#from models import SAGE,DotProductLinkPredictor\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset_name='ogbl-ddi'\n",
    "dataset=PygLinkPropPredDataset(name=dataset_name)\n",
    "data=dataset[0]\n",
    "adj_t=PygLinkPropPredDataset(name=dataset_name,transform=torch_geometric.transforms.ToSparseTensor('coo'))[0].adj_t.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_embeddings=torch.ones(data.num_nodes, 1).to(device=device)\n",
    "split_edge=dataset.get_edge_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preidctore input:  torch.Size([10, 256]) torch.Size([10, 256])\n",
      "a_t shape:  torch.Size([10, 256])\n",
      "out shape:  torch.Size([10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\models.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  a_t=torch.tensor(x_i*x_j)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7310, 0.7311, 0.7311,\n",
       "        0.7311], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize our model and LinkPredictor\n",
    "hidden_dimension = 256\n",
    "model = models.SAGE(1, hidden_dimension, hidden_dimension, 7, 0.5).to(device)\n",
    "predictor = models.DotProductLinkPredictor().to(device)\n",
    "\n",
    "# Run our initial \"node features\" through the GNN to get node embeddings\n",
    "model.eval()\n",
    "predictor.eval()\n",
    "h = model(initial_embeddings, adj_t)\n",
    "\n",
    "# Randomly sample some training edges and pass them through our basic predictor\n",
    "torch.manual_seed(1955)\n",
    "idx = torch.randperm(split_edge['train']['edge'].size(0))[:10]\n",
    "edges = split_edge['train']['edge'][idx].t()\n",
    "predictor(h[edges[0]], h[edges[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_batch(all_pos_train_edges,perm,edge_index):\n",
    "    pos_edges=all_pos_train_edges[perm].t().to(device)\n",
    "\n",
    "    #produce as many negative edges as positive edges\n",
    "    neg_edges=negative_sampling(edge_index, num_neg_samples=perm.shape[0], method='dense').to(device)\n",
    "    training_edges=torch.cat([pos_edges, neg_edges], dim=1)\n",
    "\n",
    "    pos_labels=torch.ones(pos_edges.shape[1], dtype=torch.float, device=device)\n",
    "    neg_labels=torch.zeros(neg_edges.shape[1], dtype=torch.float, device=device)\n",
    "\n",
    "    training_labels=torch.cat([pos_labels, neg_labels], dim=0).to(device)\n",
    "\n",
    "    return training_edges, training_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a training batch of size 64 produces a training batch with size 128--> produces 64 real edges and 64 fake edges (total 64 training examples)\n",
    "src_edges= [1 X 128]-->64 real and 64 fake edges of source\n",
    "dest_edges=[1 X 128]--> 64 real and 64 fake destinations\n",
    "\n",
    "training edges=[src_edges,\n",
    "                dest_edges]= [ 2 X \n",
    "                                [1 X 128]\n",
    "                                ]\n",
    "\n",
    "training_labels=[1 X 128] 64 ones and 64 zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 330,  336,  522, 1778,  259,  894, 2503,  106,  558, 1361,  216, 1816,\n",
       "         353, 2127, 3972, 3887, 2484, 3089,  993,   68, 2429, 2595,   37,  631,\n",
       "          38, 3254, 2875,  395, 2782,  292, 3606, 3498, 1004, 2211, 4112,  523,\n",
       "         224, 3312, 2492, 3957, 3792,  924, 2986, 2091,  159, 4002, 1666, 2858,\n",
       "        2955, 3374,  212, 1010, 1295, 3478,  945,  195, 2861, 3865, 4000,  868,\n",
       "        3946, 3532, 4039,  505,  547,  731,   36, 2736, 1807, 3896, 2781, 1179,\n",
       "        3667, 1832, 4038,  891, 1282, 1072, 2511,  601, 3702, 1454, 1732, 3877,\n",
       "        2020, 2808, 2404, 1020, 3692, 2892,  345, 2398, 1839, 2810, 3537, 1604,\n",
       "        3895, 4007, 1202,  428,   80, 3331, 1781, 2007, 3268, 2209, 3805, 2820,\n",
       "        3253,  396, 3012, 3578,  305, 2122, 3650,   70, 3353, 1710,  564, 3297,\n",
       "        1867, 1017, 3683, 2390,  705, 1294,  686, 2965])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=64\n",
    "create_train_batch(split_edge['train']['edge'],torch.randperm(n=split_edge['train']['edge'].size(0))[:batch_size],data.edge_index)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, predictor, x, adj_t, split_edge, loss_fn, optimizer, batch_size, num_epochs):\n",
    "  # adj_t isn't used everywhere in PyG yet, so we switch back to edge_index for negative sampling\n",
    "  # row, col, edge_attr = adj_t.t().coo()\n",
    "  # edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "  edge_index=PygLinkPropPredDataset(name='ogbl-ddi')[0].edge_index.to(device)\n",
    "  model.train()\n",
    "  predictor.train()\n",
    "\n",
    "  model.reset_parameters()\n",
    "  predictor.reset_parameters()\n",
    "\n",
    "  all_pos_train_edges = split_edge['train']['edge']\n",
    "  for epoch in range(num_epochs):\n",
    "    epoch_total_loss = 0\n",
    "    for perm in DataLoader(range(all_pos_train_edges.shape[0]), batch_size,\n",
    "                           shuffle=True):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      train_edge, train_label = create_train_batch(all_pos_train_edges, perm, edge_index)\n",
    "      print(\"training edge shape is\", train_edge.shape)\n",
    "      print(\"training label shape is\", train_label.shape)\n",
    "\n",
    "      h = model(x, adj_t)\n",
    "\n",
    "      # Get predictions for our batch and compute the loss\n",
    "      print(h[train_edge[0]].shape)\n",
    "      print(h[train_edge[0]])\n",
    "      preds = predictor(h[train_edge[0]], h[train_edge[1]])\n",
    "      print(preds.shape, preds)\n",
    "      loss = loss_fn(preds, train_label)\n",
    "\n",
    "      epoch_total_loss += loss.item()\n",
    "\n",
    "      # Update our parameters\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "      torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "    print(f'Epoch {epoch} has loss {round(epoch_total_loss, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Expected input format of Evaluator for ogbl-ddi\n",
      "{'y_pred_pos': y_pred_pos, 'y_pred_neg': y_pred_neg}\n",
      "- y_pred_pos: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "- y_pred_neg: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "y_pred_pos is the predicted scores for positive edges.\n",
      "y_pred_neg is the predicted scores for negative edges.\n",
      "Note: As the evaluation metric is ranking-based, the predicted scores need to be different for different edges.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#turn off gradient tracking for test\n",
    "@torch.no_grad()\n",
    "def test(model, predictor, x, adj_t, split_edge, evaluator, batch_size):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    \n",
    "    h = model(x, adj_t)\n",
    "\n",
    "    pos_eval_edge = split_edge['edge'].to(device)\n",
    "    neg_eval_edge = split_edge['edge_neg'].to(device)\n",
    "\n",
    "    pos_eval_preds = []\n",
    "    for perm in DataLoader(range(pos_eval_edge.shape[0]), batch_size):\n",
    "        edge = pos_eval_edge[perm].t()\n",
    "        pos_eval_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_eval_pred = torch.cat(pos_eval_preds, dim=0)\n",
    "\n",
    "    neg_eval_preds = []\n",
    "    for perm in DataLoader(range(neg_eval_edge.size(0)), batch_size):\n",
    "        edge = neg_eval_edge[perm].t()\n",
    "        print(edge)\n",
    "        neg_eval_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_eval_pred = torch.cat(neg_eval_preds, dim=0)\n",
    "\n",
    "    total_preds = torch.cat((pos_eval_pred, neg_eval_pred), dim=0)\n",
    "    labels = torch.cat((torch.ones_like(pos_eval_pred), torch.zeros_like(neg_eval_pred)), dim=0)\n",
    "    acc = accuracy(total_preds, labels)\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30, 40, 50]:\n",
    "        evaluator.K = K\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_eval_pred,\n",
    "            'y_pred_neg': neg_eval_pred,\n",
    "        })[f'hits@{K}']\n",
    "        results[f'Hits@{K}'] = (valid_hits)\n",
    "    results['Accuracy'] = acc\n",
    "\n",
    "    return results\n",
    "eval = Evaluator(name='ogbl-ddi')\n",
    "# ogb Evaluators can be invoked to get their expected format\n",
    "print(eval.expected_input_format) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n",
      "tensor([[ 0.0092, -0.0774, -0.0280,  ...,  0.0760, -0.0172, -0.0771],\n",
      "        [ 0.0063, -0.0772, -0.0332,  ...,  0.0777, -0.0157, -0.0736],\n",
      "        [ 0.0093, -0.0785, -0.0305,  ...,  0.0788, -0.0172, -0.0773],\n",
      "        [ 0.0082, -0.0773, -0.0291,  ...,  0.0757, -0.0208, -0.0757]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "preidctore input:  torch.Size([4, 256]) torch.Size([4, 256])\n",
      "a_t shape:  torch.Size([4, 256])\n",
      "out shape:  torch.Size([4])\n",
      "torch.Size([4]) tensor([0.7297, 0.7309, 0.7281, 0.7309], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\models.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  a_t=torch.tensor(x_i*x_j)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\scratch.ipynb Cell 10\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m             \u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39mparameters())  \u001b[39m+\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m             \u001b[39mlist\u001b[39m(predictor\u001b[39m.\u001b[39mparameters()), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train(model, predictor, initial_embeddings, adj_t, split_edge, torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mBCELoss(), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m       optimizer, \u001b[39m2\u001b[39;49m, \u001b[39m5\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m test(model, predictor, initial_embeddings, adj_t, split_edge[\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m], Evaluator(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mogbl-ddi\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m64\u001b[39m\u001b[39m*\u001b[39m\u001b[39m1024\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\scratch.ipynb Cell 10\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m epoch_total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Update our parameters\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m1.0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(predictor\u001b[39m.\u001b[39mparameters(), \u001b[39m1.0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, initial_embeddings, adj_t, split_edge, torch.nn.BCELoss(), \n",
    "      optimizer, 64*1024, 5)\n",
    "test(model, predictor, initial_embeddings, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
