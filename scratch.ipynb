{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\utils\\sparse.py:176: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ..\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:56.)\n",
      "  return adj.to_sparse_csr()\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "import torch_geometric \n",
    "import myutils\n",
    "import models\n",
    "#from models import SAGE,DotProductLinkPredictor\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset_name='ogbl-ddi'\n",
    "dataset=PygLinkPropPredDataset(name=dataset_name)\n",
    "data=dataset[0]\n",
    "adj_t=PygLinkPropPredDataset(name=dataset_name,transform=torch_geometric.transforms.ToSparseTensor('coo'))[0].adj_t.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_embeddings=torch.ones(data.num_nodes, 1).to(device=device)\n",
    "split_edge=dataset.get_edge_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7310, 0.7311, 0.7311,\n",
       "        0.7311], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize our model and LinkPredictor\n",
    "hidden_dimension = 256\n",
    "model = models.SAGE(1, hidden_dimension, hidden_dimension, 7, 0.5).to(device)\n",
    "predictor = models.DotProductLinkPredictor().to(device)\n",
    "\n",
    "# Run our initial \"node features\" through the GNN to get node embeddings\n",
    "model.eval()\n",
    "predictor.eval()\n",
    "h = model(initial_embeddings, adj_t)\n",
    "\n",
    "# Randomly sample some training edges and pass them through our basic predictor\n",
    "torch.manual_seed(1955)\n",
    "idx = torch.randperm(split_edge['train']['edge'].size(0))[:10]\n",
    "edges = split_edge['train']['edge'][idx].t()\n",
    "predictor(h[edges[0]], h[edges[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_batch(all_pos_train_edges,perm,edge_index):\n",
    "    pos_edges=all_pos_train_edges[perm].t().to(device)\n",
    "\n",
    "    #produce as many negative edges as positive edges\n",
    "    neg_edges=negative_sampling(edge_index, num_neg_samples=perm.shape[0], method='dense').to(device)\n",
    "    training_edges=torch.cat([pos_edges, neg_edges], dim=1)\n",
    "\n",
    "    pos_labels=torch.ones(pos_edges.shape[1], dtype=torch.float, device=device)\n",
    "    neg_labels=torch.zeros(neg_edges.shape[1], dtype=torch.float, device=device)\n",
    "\n",
    "    training_labels=torch.cat([pos_labels, neg_labels], dim=0).to(device)\n",
    "\n",
    "    return training_edges, training_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a training batch of size 64 produces a training batch with size 128--> produces 64 real edges and 64 fake edges (total 64 training examples)\n",
    "src_edges= [1 X 128]-->64 real and 64 fake edges of source\n",
    "dest_edges=[1 X 128]--> 64 real and 64 fake destinations\n",
    "\n",
    "training edges=[src_edges,\n",
    "                dest_edges]= [ 2 X \n",
    "                                [1 X 128]\n",
    "                                ]\n",
    "\n",
    "training_labels=[1 X 128] 64 ones and 64 zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 330,  336,  522, 1778,  259,  894, 2503,  106,  558, 1361,  216, 1816,\n",
       "         353, 2127, 3972, 3887, 2484, 3089,  993,   68, 2429, 2595,   37,  631,\n",
       "          38, 3254, 2875,  395, 2782,  292, 3606, 3498, 1004, 2211, 4112,  523,\n",
       "         224, 3312, 2492, 3957, 3792,  924, 2986, 2091,  159, 4002, 1666, 2858,\n",
       "        2955, 3374,  212, 1010, 1295, 3478,  945,  195, 2861, 3865, 4000,  868,\n",
       "        3946, 3532, 4039,  505,  226, 1849, 1071, 1322,  673, 4254, 1212, 1469,\n",
       "        2895, 1965, 2712,  823,  985, 4251, 3261, 3218, 3165, 1693, 1085, 2314,\n",
       "         836, 4174, 3895,  666, 1438, 3082,  497,  954, 4176, 3276, 3352, 3070,\n",
       "        1310,  116, 3307, 1956,  927,  212,  880,   51, 2359,  634, 4143,  187,\n",
       "        1613,  462, 3401, 3519, 1632, 1324, 4220, 1880, 1462, 2539, 1070, 3927,\n",
       "        3314, 3328, 3851, 1932, 2820, 3365, 2912, 3551])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=64\n",
    "create_train_batch(split_edge['train']['edge'],torch.randperm(n=split_edge['train']['edge'].size(0))[:batch_size],data.edge_index)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, predictor, x, adj_t, split_edge, loss_fn, optimizer, batch_size, num_epochs):\n",
    "  # adj_t isn't used everywhere in PyG yet, so we switch back to edge_index for negative sampling\n",
    "  # row, col, edge_attr = adj_t.t().coo()\n",
    "  # edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "  edge_index=PygLinkPropPredDataset(name='ogbl-ddi')[0].edge_index.to(device)\n",
    "  model.train()\n",
    "  predictor.train()\n",
    "\n",
    "  model.reset_parameters()\n",
    "  predictor.reset_parameters()\n",
    "  loss_per_epoch = []\n",
    "  all_pos_train_edges = split_edge['train']['edge']\n",
    "  for epoch in range(num_epochs):\n",
    "    epoch_total_loss = 0\n",
    "    for perm in DataLoader(range(all_pos_train_edges.shape[0]), batch_size,\n",
    "                           shuffle=True):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      train_edge, train_label = create_train_batch(all_pos_train_edges, perm, edge_index)\n",
    "\n",
    "\n",
    "      h = model(x, adj_t)\n",
    "\n",
    "      # Get predictions for our batch and compute the loss\n",
    "      preds = predictor(h[train_edge[0]], h[train_edge[1]])\n",
    "      loss = loss_fn(preds, train_label)\n",
    "\n",
    "      epoch_total_loss += loss.item()\n",
    "\n",
    "      # Update our parameters\n",
    "      # pass the loss of the current training batch backwards\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "      torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "    loss_per_epoch.append(epoch_total_loss)\n",
    "    myutils.draw_metric_per_epoch(loss_per_epoch, \"Loss per epoch\", \"Loss\", \"Epoch\", \"loss_per_epoch\")\n",
    "    print(f'Epoch {epoch} has loss {round(epoch_total_loss, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Expected input format of Evaluator for ogbl-ddi\n",
      "{'y_pred_pos': y_pred_pos, 'y_pred_neg': y_pred_neg}\n",
      "- y_pred_pos: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "- y_pred_neg: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "y_pred_pos is the predicted scores for positive edges.\n",
      "y_pred_neg is the predicted scores for negative edges.\n",
      "Note: As the evaluation metric is ranking-based, the predicted scores need to be different for different edges.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#turn off gradient tracking for test\n",
    "@torch.no_grad()\n",
    "def test(model, predictor, x, adj_t, split_edge, evaluator, batch_size):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    \n",
    "    h = model(x, adj_t)\n",
    "\n",
    "    pos_eval_edge = split_edge['edge'].to(device)\n",
    "    neg_eval_edge = split_edge['edge_neg'].to(device)\n",
    "\n",
    "    pos_eval_preds = []\n",
    "    for perm in DataLoader(range(pos_eval_edge.shape[0]), batch_size):\n",
    "        edge = pos_eval_edge[perm].t()\n",
    "        pos_eval_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_eval_pred = torch.cat(pos_eval_preds, dim=0)\n",
    "\n",
    "    neg_eval_preds = []\n",
    "    for perm in DataLoader(range(neg_eval_edge.size(0)), batch_size):\n",
    "        edge = neg_eval_edge[perm].t()\n",
    "        print(edge)\n",
    "        neg_eval_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_eval_pred = torch.cat(neg_eval_preds, dim=0)\n",
    "\n",
    "    total_preds = torch.cat((pos_eval_pred, neg_eval_pred), dim=0)\n",
    "    labels = torch.cat((torch.ones_like(pos_eval_pred), torch.zeros_like(neg_eval_pred)), dim=0)\n",
    "    acc = models.BinaryAccuracy(total_preds, labels)\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30, 40, 50]:\n",
    "        evaluator.K = K\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_eval_pred,\n",
    "            'y_pred_neg': neg_eval_pred,\n",
    "        })[f'hits@{K}']\n",
    "        results[f'Hits@{K}'] = (valid_hits)\n",
    "    results['Accuracy'] = acc\n",
    "\n",
    "    return results\n",
    "eval = Evaluator(name='ogbl-ddi')\n",
    "# ogb Evaluators can be invoked to get their expected format\n",
    "print(eval.expected_input_format) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss 11.7124\n",
      "Epoch 1 has loss 10.2555\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\scratch.ipynb Cell 10\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m             \u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39mparameters())  \u001b[39m+\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m             \u001b[39mlist\u001b[39m(predictor\u001b[39m.\u001b[39mparameters()), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train(model, predictor, initial_embeddings, adj_t, split_edge, torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mBCELoss(), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m       optimizer, \u001b[39m64\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m1024\u001b[39;49m, \u001b[39m5\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m test(model, predictor, initial_embeddings, adj_t, split_edge[\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m], Evaluator(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mogbl-ddi\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m64\u001b[39m\u001b[39m*\u001b[39m\u001b[39m1024\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\scratch.ipynb Cell 10\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X25sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X25sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m train_edge, train_label \u001b[39m=\u001b[39m create_train_batch(all_pos_train_edges, perm, edge_index)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X25sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m h \u001b[39m=\u001b[39m model(x, adj_t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X25sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Get predictions for our batch and compute the loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pchrk/OneDrive/Desktop/pms%20cs/2nd%20semester/SOCIAL%20NETWORKS/ddi/scratch.ipynb#X25sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m preds \u001b[39m=\u001b[39m predictor(h[train_edge[\u001b[39m0\u001b[39m]], h[train_edge[\u001b[39m1\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\2nd semester\\SOCIAL NETWORKS\\ddi\\models.py:58\u001b[0m, in \u001b[0;36mSAGE.forward\u001b[1;34m(self, x, adj_t)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, adj_t):\n\u001b[0;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m---> 58\u001b[0m         x \u001b[39m=\u001b[39m conv(x, adj_t)\n\u001b[0;32m     59\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     60\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m    128\u001b[0m     x \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mrelu(), x[\u001b[39m1\u001b[39m])\n\u001b[0;32m    130\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, size\u001b[39m=\u001b[39;49msize)\n\u001b[0;32m    132\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_l(out)\n\u001b[0;32m    134\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:435\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m         edge_index, msg_aggr_kwargs \u001b[39m=\u001b[39m res\n\u001b[1;32m--> 435\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage_and_aggregate(edge_index, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmsg_aggr_kwargs)\n\u001b[0;32m    436\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_and_aggregate_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m    437\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (edge_index, msg_aggr_kwargs), out)\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:150\u001b[0m, in \u001b[0;36mSAGEConv.message_and_aggregate\u001b[1;34m(self, adj_t, x)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(adj_t, SparseTensor):\n\u001b[0;32m    149\u001b[0m     adj_t \u001b[39m=\u001b[39m adj_t\u001b[39m.\u001b[39mset_value(\u001b[39mNone\u001b[39;00m, layout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 150\u001b[0m \u001b[39mreturn\u001b[39;00m spmm(adj_t, x[\u001b[39m0\u001b[39;49m], reduce\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggr)\n",
      "File \u001b[1;32mc:\\Users\\pchrk\\OneDrive\\Desktop\\pms cs\\NLP\\NLP\\nlp_venv\\lib\\site-packages\\torch_geometric\\utils\\spmm.py:80\u001b[0m, in \u001b[0;36mspmm\u001b[1;34m(src, other, reduce)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39m# Use the default code path for `sum` reduction (works on CPU/GPU):\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mmm(src, other)\n\u001b[0;32m     82\u001b[0m \u001b[39m# Use the default code path with custom reduction (works on CPU):\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m src\u001b[39m.\u001b[39mlayout \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39msparse_csr \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m src\u001b[39m.\u001b[39mis_cuda:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            list(model.parameters())  +\n",
    "            list(predictor.parameters()), lr=0.01)\n",
    "train(model, predictor, initial_embeddings, adj_t, split_edge, torch.nn.BCELoss(), \n",
    "      optimizer, 64*1024, 5)\n",
    "test(model, predictor, initial_embeddings, adj_t, split_edge[\"valid\"], Evaluator(name='ogbl-ddi'), 64*1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
